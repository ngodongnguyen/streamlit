import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import html
import time

# --- Cáº¥u hÃ¬nh API Key Groq ---
groq_key = st.secrets.get("GROQ_API_KEY") or st.secrets.get("api_keys", {}).get("GROQ_API_KEY")
if not groq_key:
    st.error("âŒ KhÃ´ng tÃ¬m tháº¥y GROQ_API_KEY trong secrets.")
    st.stop()

# --- HÃ m gá»i Groq API ---
def call_groq(prompt, model="llama3-70b-8192"):  # âœ… Model hiá»‡n hÃ nh máº¡nh nháº¥t
    try:
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {groq_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": model,
            "messages": [
                {"role": "system", "content": "Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn trÃ­ch xuáº¥t thÃ´ng tin tá»« ná»™i dung web."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 1024,
        }
        response = requests.post(url, headers=headers, json=data)

        if response.status_code != 200:
            st.warning(f"âš ï¸ Groq tráº£ lá»—i {response.status_code}: {response.text[:200]}...")
        response.raise_for_status()

        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Lá»—i gá»i Groq API: {e}"

# --- HÃ m há»— trá»£ láº¥y ná»™i dung trang web ---
def get_website_content(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept': 'text/html',
            'Connection': 'keep-alive'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        content_parts = []
        if soup.title:
            content_parts.append(soup.title.get_text(strip=True))
        meta_description = soup.find('meta', attrs={'name': 'description'})
        if meta_description and 'content' in meta_description.attrs:
            content_parts.append(meta_description['content'])

        paragraphs = soup.find_all('p')
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        list_items = soup.find_all('li')

        for tag in paragraphs + headings + list_items:
            text = tag.get_text(separator=' ', strip=True)
            if text:
                content_parts.append(text)

        full_content = " ".join(content_parts)
        return full_content[:7000]
    except Exception as e:
        st.warning(f"âš ï¸ Lá»—i khi truy cáº­p {url}: {e}")
        return None

# --- Giao diá»‡n ---
st.set_page_config(page_title="ğŸ“„ MÃ´ Táº£ Dá»± Ãn", layout="wide")
st.title("ğŸ“„ MÃ´ Táº£ Dá»± Ãn Tá»« URL")
st.caption("Nháº­p danh sÃ¡ch URL Ä‘á»ƒ AI trÃ­ch xuáº¥t mÃ´ táº£ sáº£n pháº©m/dá»‹ch vá»¥ chÃ­nh vÃ  thÃ´ng tin chi tiáº¿t.")

urls_input = st.text_area("ğŸ“¥ Nháº­p danh sÃ¡ch URL (má»—i dÃ²ng 1 link):", height=150)

if st.button("ğŸš€ PhÃ¢n tÃ­ch"):
    if not urls_input.strip():
        st.warning("âš ï¸ Vui lÃ²ng nháº­p Ã­t nháº¥t 1 URL.")
    else:
        urls = [u.strip() for u in urls_input.split('\n') if u.strip()]
        results = []
        results.append("Website\tNgÃ¡ch\tNÄƒm thÃ nh láº­p\tÄá»‹a chá»‰ trá»¥ sá»Ÿ chÃ­nh\tMÃ´ táº£")

        with st.spinner("ğŸ” Äang phÃ¢n tÃ­ch..."):
            for url in urls:
                st.write(f"ğŸ”— Äang xá»­ lÃ½: {url}")
                content = get_website_content(url)

                if content:
                    safe_content = html.unescape(content[:5000])
                    prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch trang web Ä‘á»ƒ chá»n lá»c ngÃ¡ch phÃ¹ há»£p cho affiliate marketing.

Nhiá»‡m vá»¥ cá»§a báº¡n lÃ : tá»« ná»™i dung trang web dÆ°á»›i Ä‘Ã¢y, hÃ£y **tráº£ vá» duy nháº¥t 1 dÃ²ng gá»“m 5 cá»™t**, cÃ¡ch nhau báº±ng dáº¥u tab (`\\t`):

| Website | NgÃ¡ch | NÄƒm thÃ nh láº­p | Äá»‹a chá»‰ trá»¥ sá»Ÿ chÃ­nh | MÃ´ táº£ sáº£n pháº©m chÃ­nh |

Náº¿u khÃ´ng rÃµ thÃ´ng tin, ghi "KhÃ´ng xÃ¡c Ä‘á»‹nh".

---
URL: {url}
Ná»™i dung:
{safe_content}
                    """
                    try:
                        response_text = call_groq(prompt)
                        result_line = response_text.strip().split('\n')[-1]
                        results.append(result_line)
                    except Exception as e:
                        st.warning(f"âŒ Lá»—i xá»­ lÃ½ {url}: {e}")
                        results.append(f"{url}\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh")
                else:
                    results.append(f"{url}\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh\tKhÃ´ng xÃ¡c Ä‘á»‹nh")

                time.sleep(1)

        st.success("âœ… HoÃ n táº¥t.")
        final_output = "\n".join(results)
        st.text_area("ğŸ“‹ Káº¿t quáº£ phÃ¢n tÃ­ch", value=final_output, height=400)
